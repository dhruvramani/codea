{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"run.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"pOkUMRXBx6fx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611410992694,"user_tz":-330,"elapsed":1211,"user":{"displayName":"Dhruv Ramani","photoUrl":"","userId":"05122263508697045795"}},"outputId":"2718b010-21ef-4237-d198-ba1bc1dae86c"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/My Drive/Startup/code/code_completion\n"," \n","# Next 2 for the TPU - remove if it's not a TPU runtime.\n","# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o /root/.cache/pytorch-xla-env-setup.py\n","# !python /root/.cache/pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n","\n","!pip3 install torch transformers pytorch-lightning datasets pandas autopep8 rouge_score"],"execution_count":1,"outputs":[{"output_type":"stream","text":["      Successfully uninstalled pyarrow-0.14.1\n","Successfully installed PyYAML-5.4.1 aiohttp-3.7.3 async-timeout-3.0.1 autopep8-1.5.4 datasets-1.2.1 fsspec-0.8.5 idna-ssl-1.1.0 multidict-5.1.0 pyarrow-2.0.0 pycodestyle-2.6.0 pytorch-lightning-1.1.5 rouge-score-0.0.4 sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.2.2 xxhash-2.0.0 yarl-1.6.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CbCTVfHENDUM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74cf00bb-01b1-4c09-bc54-1b931a80d88d"},"source":["%autoreload 2\n","!sudo python3 train.py --model gpt2 --batch_size 6 --dataset all --gpus -1 --precision 16"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-01-23 17:02:05.643707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","D BIGCODE : Using cache.\n","D ETH150 : Using cache.\n","D CS-Uni : Using cache.\n","GPU available: True, used: True\n","TPU available: None, using: 0 TPU cores\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Using native 16bit precision.\n","\n","  | Name  | Type            | Params\n","------------------------------------------\n","0 | model | GPT2LMHeadModel | 83.3 M\n","------------------------------------------\n","83.3 M    Trainable params\n","0         Non-trainable params\n","83.3 M    Total params\n","Validation sanity check:   0% 0/2 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Epoch 0: : 57it [01:09,  1.21s/it, loss=6.06, v_num=46]"],"name":"stdout"}]}]}